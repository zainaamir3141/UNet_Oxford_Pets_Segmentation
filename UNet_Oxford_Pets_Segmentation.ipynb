{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Image Segmentation - Oxford Pets\n\nU-Net architecture for semantic segmentation on the Oxford-IIIT Pet Dataset.\n\n## Features\n\n- U-Net architecture\n- Semantic segmentation\n- Encoder-decoder\n- Skip connections\n- Pet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzfXqn4T1T9j",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752361668948,
     "user_tz": 240,
     "elapsed": 49586,
     "user": {
      "displayName": "Zain Aamir",
      "userId": "06391012383926133535"
     }
    },
    "outputId": "36319c35-c74e-4cb8-e599-b1cadb9ba3e9"
   },
   "outputs": [],
   "source": "# Download Oxford-IIIT Pet Dataset (images + annotations)\n!curl -L -O https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n!curl -L -O https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n\n# Check if files are downloaded correctly\n!ls -lh images.tar.gz annotations.tar.gz\n\n# Extract"
  },
  {
   "cell_type": "code",
   "source": "import os\n\ninput_dir = \"images/\"\ntarget_dir = \"annotations/trimaps/\"\nimg_size = (160, 160)\nnum_classes = 3\nbatch_size = 32\n\ninput_img_paths = sorted([\n    os.path.join(input_dir, fname)\n    for fname in os.listdir(input_dir)\n    if fname.endswith(\".jpg\")\n])\n\ntarget_img_paths = sorted([\n    os.path.join(target_dir, fname)\n    for fname in os.listdir(target_dir)\n    if fname.endswith(\".png\") and not fname.startswith(\".\")\n])",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IgLefNgO2gQo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752362624184,
     "user_tz": 240,
     "elapsed": 34,
     "user": {
      "displayName": "Zain Aamir",
      "userId": "06391012383926133535"
     }
    },
    "outputId": "c7c4f2c5-a6ea-4eb6-a0a8-cc5c95a65a63"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from IPython.display import Image, display\nfrom keras.utils import load_img\nfrom PIL import ImageOps\n\n# Display input image #7\ndisplay(Image(filename=input_img_paths[9]))\n\n# Display auto-contrast version of corresponding target (per-pixel categories)\nimg = ImageOps.autocontrast(load_img(target_img_paths[9]))",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "id": "Ef7T17Iw5SWr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752362633219,
     "user_tz": 240,
     "elapsed": 80,
     "user": {
      "displayName": "Zain Aamir",
      "userId": "06391012383926133535"
     }
    },
    "outputId": "06b41a1a-2868-43fb-d951-3332862b1c34"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import keras\nimport numpy as np\nfrom tensorflow import data as tf_data\nfrom tensorflow import image as tf_image\nfrom tensorflow import io as tf_io\n\n\ndef get_dataset(batch_size, img_size, input_img_paths, target_img_paths,\n                max_dataset_len=None):\n    \"\"\"Returns a TF Dataset.\"\"\"\n\n    def load_img_masks(input_img_path, target_img_path):\n        input_img = tf_io.read_file(input_img_path)",
   "metadata": {
    "id": "shBf193v6YLk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from keras import layers\n\n\ndef get_model(img_size, num_classes):\n    inputs = keras.Input(shape=img_size + (3,))\n    \n    # First half of the network: downsampling inputs\n    # Entry block\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n    previous_block_activation = x  # Set aside residual\n    \n    # Blocks",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RTfeNwUVJVOK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752362682046,
     "user_tz": 240,
     "elapsed": 395,
     "user": {
      "displayName": "Zain Aamir",
      "userId": "06391012383926133535"
     }
    },
    "outputId": "941b1baa-c91c-4bc4-be28-9ca4e22fcc28"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import random\n\n# Split our img paths into a training and a validation set\nval_samples = 1000\nrandom.Random(1337).shuffle(input_img_paths)\nrandom.Random(1337).shuffle(target_img_paths)\n\ntrain_input_img_paths = input_img_paths[:-val_samples]\ntrain_target_img_paths = target_img_paths[:-val_samples]\n\nval_input_img_paths = input_img_paths[-val_samples:]\nval_target_img_paths = target_img_paths[-val_samples:]",
   "metadata": {
    "id": "_GygbZFF5AZT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Configure the model for training\n# We use the \"sparse\" version of categorical_crossentropy\n# because our target data is integers.\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-4),\n    loss=\"sparse_categorical_crossentropy\"\n)\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\",\n                                  save_best_only=True)\n]\n\n# Train the model, doing validation at the end of each epoch.\nepochs = 50\nmodel.fit(\n    train_dataset,\n    epochs=epochs,\n    validation_data=valid_dataset,\n    callbacks=callbacks,\n    verbose=2,\n)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tf1rL1f77ay_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1752363237392,
     "user_tz": 240,
     "elapsed": 532315,
     "user": {
      "displayName": "Zain Aamir",
      "userId": "06391012383926133535"
     }
    },
    "outputId": "65076471-3f97-4290-8eba-c60104d41cd4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate predictions for all images in the validation set\nval_dataset = get_dataset(batch_size, img_size, val_input_img_paths,\n                         val_target_img_paths)\nval_preds = model.predict(val_dataset)\n\n\ndef display_mask(i):\n    \"\"\"Quick utility to display a model's prediction.\"\"\"\n    mask = np.argmax(val_preds[i], axis=-1)\n    mask = np.expand_dims(mask, axis=-1)\n    img = ImageOps.autocontrast(keras.utils.array_to_img(mask))",
   "metadata": {
    "id": "-x8XTvl29N_H"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyMhn9liqXFNAegRY/SORFFW"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}